{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247b1836-64b0-4362-86c2-78cdb2560f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae07a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import wandb\n",
    "import tifffile\n",
    "import psutil\n",
    "from glob import glob\n",
    "import time\n",
    "import datetime\n",
    "import imageio\n",
    "from sys import stdout\n",
    "from typing import List, Tuple, Optional\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de282a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.scale = 4                    # Upscaling factor\n",
    "        self.epoch = 500                  # Number of epochs\n",
    "        self.epoch_step = 50              # T_0 for CosineAnnealingWarmRestarts\n",
    "        self.patch_size = 192              # Training crop size\n",
    "        self.batch_size = 16              # Batch size\n",
    "        self.lr = 0.0001                  # Learning rate\n",
    "        self.save_freq = 10               # Model saving frequency\n",
    "        self.print_freq = 1               # Validation frequency\n",
    "        self.itersPerEpoch = 200          # Iterations per epoch\n",
    "        self.iterCyclesPerEpoch = 1       # Iteration cycles per epoch\n",
    "        self.valNum = 5                   # Number of validation samples\n",
    "        self.checkpoint_dir = './checkpoints'  # Checkpoints directory\n",
    "        self.test_dir = './Dataset/Bentheimer_mixed_fw90/Test'          # Test directory\n",
    "        self.test_save_dir = './test_results'  # Test results directory\n",
    "        self.test_temp_save_dir = './test_temp'  # Temp test results directory\n",
    "        self.modelName = 'DualSR_mixed90'         # Model name\n",
    "        self.dataset_dir = './Dataset/Bentheimer_mixed_fw90/Train'  # Dataset directory\n",
    "        self.continue_train = False       # Continue training from checkpoint\n",
    "        self.continueEpoch = 0            # Epoch to continue from\n",
    "        self.use_best_model = True        # Use best model for testing\n",
    "        self.phase = 'train'              # Phase: train or test\n",
    "        self.augFlag = True               # Data augmentation flag\n",
    "        self.valTest = False              # Validation test flag\n",
    "        self.numResBlocks = 16             # Number of residual blocks\n",
    "        self.ngsrf = 64                   # Number of filters for generator SR\n",
    "        self.gpuIDs = \"0\"                 # GPU IDs to use\n",
    "        self.chunk_size = 1000            # Size of chunks for processing large images\n",
    "        self.overlap = 50                 # Overlap between chunks\n",
    "        self.wandb_api_key = None         # API key for wandb authentication\n",
    "        self.wandb_project = \"DualSR_Bentheimer_mixed90\"   # Project name for wandb\n",
    "        self.wandb_entity = None          # Optional: your wandb username or team name\n",
    "        self.eta_min = 1e-6               # Minimum learning rate for scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37c715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network components\n",
    "class InstanceNorm(nn.Module):\n",
    "    \"\"\"Instance Normalization Layer\"\"\"\n",
    "    def __init__(self, channels, eps=1e-5):\n",
    "        super(InstanceNorm, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(channels))\n",
    "        self.offset = nn.Parameter(torch.zeros(channels))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 4:  # 2D\n",
    "            mean = x.mean(dim=(2, 3), keepdim=True)\n",
    "            var = ((x - mean)**2).mean(dim=(2, 3), keepdim=True)\n",
    "        else:  # 3D\n",
    "            mean = x.mean(dim=(2, 3, 4), keepdim=True)\n",
    "            var = ((x - mean)**2).mean(dim=(2, 3, 4), keepdim=True)\n",
    "            \n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return x * self.scale.view(1, -1, 1, 1) + self.offset.view(1, -1, 1, 1)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"Residual Block for EDSR\"\"\"\n",
    "    def __init__(self, channels, kernel_size=3, norm_type='instancenorm', apply_norm=False, ndims=2):\n",
    "        super(ResBlock, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        if ndims == 2:\n",
    "            self.conv1 = nn.Conv2d(channels, channels, kernel_size, padding=padding)\n",
    "            self.conv2 = nn.Conv2d(channels, channels, kernel_size, padding=padding)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv3d(channels, channels, kernel_size, padding=padding)\n",
    "            self.conv2 = nn.Conv3d(channels, channels, kernel_size, padding=padding)\n",
    "            \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        if apply_norm:\n",
    "            if norm_type.lower() == 'batchnorm':\n",
    "                self.norm = nn.BatchNorm2d(channels) if ndims == 2 else nn.BatchNorm3d(channels)\n",
    "            elif norm_type.lower() == 'instancenorm':\n",
    "                self.norm = InstanceNorm(channels)\n",
    "            self.use_norm = True\n",
    "        else:\n",
    "            self.use_norm = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        if self.use_norm:\n",
    "            out = self.norm(out)\n",
    "            \n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    \"\"\"Upsampling module for EDSR\"\"\"\n",
    "    def __init__(self, scale, num_filters, norm_type='instancenorm', apply_norm=False, ndims=2):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.ndims = ndims\n",
    "        self.num_filters = num_filters\n",
    "        \n",
    "        if ndims == 2:\n",
    "            self.conv = nn.Conv2d(num_filters, num_filters, 3, padding=1)\n",
    "        else:\n",
    "            self.conv = nn.Conv3d(num_filters, num_filters, 3, padding=1)\n",
    "            \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        if apply_norm:\n",
    "            if norm_type.lower() == 'batchnorm':\n",
    "                self.norm = nn.BatchNorm2d(num_filters) if ndims == 2 else nn.BatchNorm3d(num_filters)\n",
    "            elif norm_type.lower() == 'instancenorm':\n",
    "                self.norm = InstanceNorm(num_filters)\n",
    "            self.use_norm = True\n",
    "        else:\n",
    "            self.use_norm = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.use_norm:\n",
    "            x = self.norm(x)\n",
    "            \n",
    "        if self.ndims == 2:\n",
    "            x = F.interpolate(x, scale_factor=self.scale, mode='nearest-exact')\n",
    "        else:\n",
    "            x = F.interpolate(x, scale_factor=self.scale, mode='nearest-exact')\n",
    "            \n",
    "        return x\n",
    "\n",
    "class Upsample1D(nn.Module):\n",
    "    \"\"\"1D Upsampling module for EDSR\"\"\"\n",
    "    def __init__(self, scale, num_filters, norm_type='instancenorm', apply_norm=False, ndims=2):\n",
    "        super(Upsample1D, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.ndims = ndims\n",
    "        self.num_filters = num_filters\n",
    "        \n",
    "        if ndims == 2:\n",
    "            self.conv = nn.Conv2d(num_filters, num_filters, 3, padding=1)\n",
    "        else:\n",
    "            self.conv = nn.Conv3d(num_filters, num_filters, 3, padding=1)\n",
    "            \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        if apply_norm:\n",
    "            if norm_type.lower() == 'batchnorm':\n",
    "                self.norm = nn.BatchNorm2d(num_filters) if ndims == 2 else nn.BatchNorm3d(num_filters)\n",
    "            elif norm_type.lower() == 'instancenorm':\n",
    "                self.norm = InstanceNorm(num_filters)\n",
    "            self.use_norm = True\n",
    "        else:\n",
    "            self.use_norm = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.use_norm:\n",
    "            x = self.norm(x)\n",
    "            \n",
    "        # Handle upsampling for 2D tensors by using scale_factor with tuple\n",
    "        if self.ndims == 2:\n",
    "            # Scale only height (first dimension after batch and channel)\n",
    "            scale_factor = (self.scale, 1)\n",
    "            x = F.interpolate(x, scale_factor=scale_factor, mode='nearest-exact')\n",
    "        else:\n",
    "            # Scale only depth (first dimension after batch and channel) for 3D\n",
    "            scale_factor = (self.scale, 1, 1)\n",
    "            x = F.interpolate(x, scale_factor=scale_factor, mode='nearest-exact')\n",
    "            \n",
    "        return x\n",
    "\n",
    "class EDSR(nn.Module):\n",
    "    \"\"\"EDSR Super-Resolution Network\"\"\"\n",
    "    def __init__(self, scale, num_filters=64, num_res_blocks=8, ndims=2):\n",
    "        super(EDSR, self).__init__()\n",
    "        self.ndims = ndims\n",
    "        \n",
    "        # First convolution layer\n",
    "        if ndims == 2:\n",
    "            self.first_conv = nn.Conv2d(1, num_filters, 3, padding=1)\n",
    "        else:\n",
    "            self.first_conv = nn.Conv3d(1, num_filters, 3, padding=1)\n",
    "            \n",
    "        # Residual blocks\n",
    "        res_blocks = []\n",
    "        for _ in range(num_res_blocks):\n",
    "            res_blocks.append(ResBlock(num_filters, 3, norm_type='instancenorm', apply_norm=False, ndims=ndims))\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "        \n",
    "        # Final feature convolution\n",
    "        if ndims == 2:\n",
    "            self.final_feature_conv = nn.Conv2d(num_filters, num_filters, 3, padding=1)\n",
    "        else:\n",
    "            self.final_feature_conv = nn.Conv3d(num_filters, num_filters, 3, padding=1)\n",
    "        \n",
    "        # Upsampling layers\n",
    "        if scale == 2:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "            ])\n",
    "        elif scale == 3:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample(3, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "            ])\n",
    "        elif scale == 4:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "                Upsample(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims)\n",
    "            ])\n",
    "        elif scale == 8:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "                Upsample(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "                Upsample(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims)\n",
    "            ])\n",
    "            \n",
    "        # Final reconstruction convolution\n",
    "        if ndims == 2:\n",
    "            self.final_conv = nn.Conv2d(num_filters, 1, 3, padding=1)\n",
    "        else:\n",
    "            self.final_conv = nn.Conv3d(num_filters, 1, 3, padding=1)\n",
    "            \n",
    "        # Output activation\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        residual = x\n",
    "        \n",
    "        x = self.res_blocks(x)\n",
    "        x = self.final_feature_conv(x)\n",
    "        x = x + residual\n",
    "        \n",
    "        for up in self.upsample:\n",
    "            x = up(x)\n",
    "            \n",
    "        x = self.final_conv(x)\n",
    "        return self.tanh(x)\n",
    "\n",
    "class EDSR1D(nn.Module):\n",
    "    \"\"\"EDSR Super-Resolution Network with 1D upsampling\"\"\"\n",
    "    def __init__(self, scale, num_filters=64, num_res_blocks=8, ndims=2):\n",
    "        super(EDSR1D, self).__init__()\n",
    "        self.ndims = ndims\n",
    "        \n",
    "        # First convolution layer\n",
    "        if ndims == 2:\n",
    "            self.first_conv = nn.Conv2d(1, num_filters, 3, padding=1)\n",
    "        else:\n",
    "            self.first_conv = nn.Conv3d(1, num_filters, 3, padding=1)\n",
    "            \n",
    "        # Residual blocks\n",
    "        res_blocks = []\n",
    "        for _ in range(num_res_blocks):\n",
    "            res_blocks.append(ResBlock(num_filters, 3, norm_type='instancenorm', apply_norm=False, ndims=ndims))\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "        \n",
    "        # Final feature convolution\n",
    "        if ndims == 2:\n",
    "            self.final_feature_conv = nn.Conv2d(num_filters, num_filters, 3, padding=1)\n",
    "        else:\n",
    "            self.final_feature_conv = nn.Conv3d(num_filters, num_filters, 3, padding=1)\n",
    "        \n",
    "        # Upsampling layers\n",
    "        if scale == 2:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample1D(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "            ])\n",
    "        elif scale == 3:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample1D(3, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "            ])\n",
    "        elif scale == 4:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample1D(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "                Upsample1D(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims)\n",
    "            ])\n",
    "        elif scale == 8:\n",
    "            self.upsample = nn.ModuleList([\n",
    "                Upsample1D(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "                Upsample1D(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims),\n",
    "                Upsample1D(2, num_filters, norm_type='instancenorm', apply_norm=False, ndims=ndims)\n",
    "            ])\n",
    "            \n",
    "        # Final reconstruction convolution\n",
    "        if ndims == 2:\n",
    "            self.final_conv = nn.Conv2d(num_filters, 1, 3, padding=1)\n",
    "        else:\n",
    "            self.final_conv = nn.Conv3d(num_filters, 1, 3, padding=1)\n",
    "            \n",
    "        # Output activation\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        residual = x\n",
    "        \n",
    "        x = self.res_blocks(x)\n",
    "        x = self.final_feature_conv(x)\n",
    "        x = x + residual\n",
    "        \n",
    "        for up in self.upsample:\n",
    "            x = up(x)\n",
    "            \n",
    "        x = self.final_conv(x)\n",
    "        return self.tanh(x)\n",
    "\n",
    "class DualSRDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for Dual Super Resolution that handles the scaling factor mismatch\n",
    "    between HR and LR datasets.\n",
    "    \n",
    "    This preserves all HR slices while ensuring proper pairing with LR slices.\n",
    "    \"\"\"\n",
    "    def __init__(self, hr_tensor, lr_tensor, scale):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hr_tensor (torch.Tensor): High resolution tensor with shape [B*scale, C, H, W]\n",
    "            lr_tensor (torch.Tensor): Low resolution tensor with shape [B, C, H/scale, W/scale]\n",
    "            scale (int): Upscaling factor\n",
    "        \"\"\"\n",
    "        self.hr_tensor = hr_tensor\n",
    "        self.lr_tensor = lr_tensor\n",
    "        self.scale = scale\n",
    "        \n",
    "        # Verify tensor shapes match our requirements\n",
    "        self.hr_batch_size = hr_tensor.shape[0]\n",
    "        self.lr_batch_size = lr_tensor.shape[0]\n",
    "        \n",
    "        assert self.hr_batch_size == self.lr_batch_size * scale, \\\n",
    "            f\"HR batch size ({self.hr_batch_size}) must be scale ({scale}) times LR batch size ({self.lr_batch_size})\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.lr_batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For each LR slice, return:\n",
    "        - The LR slice\n",
    "        - The corresponding scale HR slices\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (lr_slice, hr_slices)\n",
    "        \"\"\"\n",
    "        lr_slice = self.lr_tensor[idx]\n",
    "        \n",
    "        # Get the corresponding HR slices (there are 'scale' of them for each LR slice)\n",
    "        hr_start_idx = idx * self.scale\n",
    "        hr_end_idx = hr_start_idx + self.scale\n",
    "        hr_slices = self.hr_tensor[hr_start_idx:hr_end_idx]\n",
    "        \n",
    "        return lr_slice, hr_slices\n",
    "\n",
    "# Fixed StraightThroughRound implementation\n",
    "class StraightThroughRound(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)  # Save input for backward\n",
    "        return torch.round(x)\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Pass gradient through unchanged\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad2dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gaussian_kernel(kernel_size, sigma, n_channels, dtype):\n",
    "    \"\"\"Create a Gaussian kernel for blurring\"\"\"\n",
    "    x = torch.arange(-kernel_size // 2 + 1, kernel_size // 2 + 1, dtype=dtype)\n",
    "    g = torch.exp(-(x ** 2) / (2 * sigma ** 2))\n",
    "    g_norm2d = torch.sum(g) ** 2\n",
    "    g_kernel = torch.outer(g, g) / g_norm2d\n",
    "    g_kernel = g_kernel.reshape(1, 1, kernel_size, kernel_size)\n",
    "    g_kernel = g_kernel.repeat(n_channels, 1, 1, 1)\n",
    "    return g_kernel\n",
    "\n",
    "def apply_blur(img, kernel_size, sigma, n_channel):\n",
    "    \"\"\"Apply Gaussian blur to image\"\"\"\n",
    "    blur = _gaussian_kernel(kernel_size, sigma, n_channel, img.dtype).to(img.device)\n",
    "    img = F.conv2d(img, blur, padding=kernel_size//2, groups=n_channel)\n",
    "    return img\n",
    "\n",
    "def augment_data(image):\n",
    "    \"\"\"Apply data augmentation to input image\"\"\"\n",
    "    # Get the original device\n",
    "    device = image.device\n",
    "    \n",
    "    # Convert to PyTorch tensor if not already\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "        image = torch.from_numpy(image).float().to(device)\n",
    "        \n",
    "    # Make sure random numbers are created on the same device as the image\n",
    "    cont_factor = (torch.rand(1, device=device)*2-1)*0.2+1\n",
    "    bright_factor = (torch.rand(1, device=device)*2-1)*0.2+1\n",
    "    \n",
    "    image = image * bright_factor\n",
    "    \n",
    "    # Calculate mean across spatial dimensions\n",
    "    if len(image.shape) == 4:  # [B, C, H, W]\n",
    "        mean = torch.mean(image, dim=(2, 3), keepdim=True)\n",
    "    else:  # [B, C, D, H, W]\n",
    "        mean = torch.mean(image, dim=(2, 3, 4), keepdim=True)\n",
    "    \n",
    "    image = (image - mean) * cont_factor + mean\n",
    "    image = torch.clamp(image, -1, 1)\n",
    "    \n",
    "    # Ensure output is on the same device as input\n",
    "    return image\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=2.0):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    # Ensure both tensors are on the same device\n",
    "    if img1.device != img2.device:\n",
    "        img2 = img2.to(img1.device)\n",
    "    \n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return torch.tensor(100.0, device=img1.device)\n",
    "    return 20 * torch.log10(torch.tensor(max_val, device=img1.device) / torch.sqrt(mse))\n",
    "\n",
    "def move_to_device(tensor, device):\n",
    "    \"\"\"Move tensor to specified device if it's not already there\"\"\"\n",
    "    if tensor.device != device:\n",
    "        return tensor.to(device)\n",
    "    return tensor\n",
    "\n",
    "def process_image_in_chunks(model, image, args, device, dim='xy'):\n",
    "    \"\"\"\n",
    "    Process a large image in chunks to avoid memory issues\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        image: Input image as tensor [B, C, H, W]\n",
    "        args: Configuration arguments\n",
    "        device: Computation device (CPU/GPU)\n",
    "        dim: Dimension to process ('xy' or 'yz')\n",
    "        \n",
    "    Returns:\n",
    "        Processed image\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch, channel, height, width = image.shape\n",
    "        \n",
    "        # Set chunk size and overlap\n",
    "        chunk_size = args.chunk_size\n",
    "        overlap = args.overlap\n",
    "        \n",
    "        # For very small images, just process directly\n",
    "        if height <= chunk_size and width <= chunk_size:\n",
    "            with torch.no_grad():\n",
    "                return model(image)\n",
    "        \n",
    "        # Prepare output tensor (with higher resolution in appropriate dimension)\n",
    "        if dim == 'xy':\n",
    "            output = torch.zeros(batch, channel, height*args.scale, width*args.scale, \n",
    "                                device='cpu', dtype=torch.float32)\n",
    "        else:  # 'yz' - only upscale first dimension\n",
    "            output = torch.zeros(batch, channel, height*args.scale, width, \n",
    "                                device='cpu', dtype=torch.float32)\n",
    "        \n",
    "        # Define a weight map for blending overlapping regions\n",
    "        weight_map = torch.zeros_like(output, device='cpu')\n",
    "        \n",
    "        # Process image in horizontal chunks\n",
    "        for i in range(0, width, chunk_size-overlap):\n",
    "            # Handle last chunk boundary\n",
    "            end_i = min(i + chunk_size, width)\n",
    "            start_i = max(0, end_i - chunk_size)\n",
    "            \n",
    "            # Process image in vertical chunks\n",
    "            for j in range(0, height, chunk_size-overlap):\n",
    "                # Handle last chunk boundary\n",
    "                end_j = min(j + chunk_size, height)\n",
    "                start_j = max(0, end_j - chunk_size)\n",
    "                \n",
    "                # Extract chunk\n",
    "                chunk = image[:, :, start_j:end_j, start_i:end_i].to(device)\n",
    "                \n",
    "                # Process chunk\n",
    "                with torch.no_grad():\n",
    "                    processed_chunk = model(chunk)\n",
    "                \n",
    "                # Calculate output coordinates with upscaling\n",
    "                if dim == 'xy':\n",
    "                    out_start_j = start_j * args.scale\n",
    "                    out_end_j = end_j * args.scale\n",
    "                    out_start_i = start_i * args.scale\n",
    "                    out_end_i = end_i * args.scale\n",
    "                else:  # 'yz' - only upscale in first dimension\n",
    "                    out_start_j = start_j * args.scale\n",
    "                    out_end_j = end_j * args.scale\n",
    "                    out_start_i = start_i\n",
    "                    out_end_i = end_i\n",
    "                \n",
    "                # Create blending weights for smooth transitions\n",
    "                # Higher weight in the center, lower at edges\n",
    "                blend = torch.ones((processed_chunk.size(0), \n",
    "                                    processed_chunk.size(1),\n",
    "                                    out_end_j - out_start_j,\n",
    "                                    out_end_i - out_start_i), \n",
    "                                  device='cpu')\n",
    "                \n",
    "                # Apply edge tapering for horizontal boundaries\n",
    "                if start_i > 0:  # Left edge\n",
    "                    for x in range(overlap * args.scale):\n",
    "                        weight = 0.5 * (1 - np.cos(np.pi * x / (overlap * args.scale)))\n",
    "                        blend[:, :, :, x] = weight\n",
    "                \n",
    "                if end_i < width:  # Right edge\n",
    "                    for x in range(overlap * args.scale):\n",
    "                        weight = 0.5 * (1 - np.cos(np.pi * (overlap * args.scale - x) / (overlap * args.scale)))\n",
    "                        blend[:, :, :, -(x+1)] = weight\n",
    "                \n",
    "                # Apply edge tapering for vertical boundaries\n",
    "                if start_j > 0:  # Top edge\n",
    "                    for y in range(overlap * args.scale):\n",
    "                        weight = 0.5 * (1 - np.cos(np.pi * y / (overlap * args.scale)))\n",
    "                        blend[:, :, y, :] = blend[:, :, y, :] * weight\n",
    "                \n",
    "                if end_j < height:  # Bottom edge\n",
    "                    for y in range(overlap * args.scale):\n",
    "                        weight = 0.5 * (1 - np.cos(np.pi * (overlap * args.scale - y) / (overlap * args.scale)))\n",
    "                        blend[:, :, -(y+1), :] = blend[:, :, -(y+1), :] * weight\n",
    "                \n",
    "                # Move processed chunk to CPU\n",
    "                processed_chunk = processed_chunk.to('cpu')\n",
    "                \n",
    "                # Apply blending\n",
    "                output[:, :, out_start_j:out_end_j, out_start_i:out_end_i] += processed_chunk * blend\n",
    "                weight_map[:, :, out_start_j:out_end_j, out_start_i:out_end_i] += blend\n",
    "        \n",
    "        # Normalize by the weight map to get the final output\n",
    "        # Avoid division by zero\n",
    "        weight_map = torch.clamp(weight_map, min=1e-8)\n",
    "        output = output / weight_map\n",
    "        \n",
    "        return output\n",
    "    \n",
    "def authenticate_wandb(api_key=None, entity=None):\n",
    "    \"\"\"\n",
    "    Authenticate with wandb using API key\n",
    "    \n",
    "    Args:\n",
    "        api_key: Your wandb API key\n",
    "        entity: Optional wandb username or team name\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if authentication successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if api_key:\n",
    "            print(\"Authenticating with wandb using API key...\")\n",
    "            wandb.login(key=api_key)\n",
    "        else:\n",
    "            print(\"No API key provided. Using default wandb login...\")\n",
    "            wandb.login()\n",
    "            \n",
    "        # Verify authentication\n",
    "        if wandb.api.api_key:\n",
    "            print(f\"Successfully authenticated with wandb{' as ' + entity if entity else ''}!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Failed to authenticate with wandb.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error authenticating with wandb: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def createTrainingCubes2(args, HR, LR, batchsize, cropsize, scale):\n",
    "    \"\"\"\n",
    "    Create training cubes by extracting 3D blocks from HR/LR volumes in XY, YZ, and XZ planes,\n",
    "    then unrolling them along the batch dimension.\n",
    "    \"\"\"\n",
    "    # Allocate output:\n",
    "    #  - LR has shape [batchsize * itersPerEpoch, cropsize,         cropsize,         1]\n",
    "    #  - HR has shape [batchsize * itersPerEpoch * scale, cropsize * scale, cropsize * scale, 1]\n",
    "    batchLR = np.zeros([batchsize * args.itersPerEpoch, cropsize, cropsize, 1], dtype=np.float32)\n",
    "    batchHR = np.zeros([batchsize * args.itersPerEpoch * scale,\n",
    "                        cropsize * scale,\n",
    "                        cropsize * scale,\n",
    "                        1], dtype=np.float32)\n",
    "    \n",
    "    # We will keep two running indices:\n",
    "    #  - n  for LR slices in the batch dimension\n",
    "    #  - n2 for HR slices in the batch dimension\n",
    "    n = 0\n",
    "    n2 = 0\n",
    "\n",
    "    for i in tqdm(range(args.itersPerEpoch), desc=\"Creating Training Cubes\"):\n",
    "        # Cycle between xy, yz, and xz\n",
    "        if np.mod(i, 3) == 0:\n",
    "            # XY-style block:\n",
    "            #    block shape:    [batchsize, cropsize,         cropsize,         1]\n",
    "            #    blockHR shape: [batchsize*scale, cropsize*scale, cropsize*scale, 1]\n",
    "            x = int(np.floor(np.random.rand() * (LR.shape[0] - batchsize)))\n",
    "            y = int(np.floor(np.random.rand() * (LR.shape[1] - cropsize)))\n",
    "            z = int(np.floor(np.random.rand() * (LR.shape[2] - cropsize)))\n",
    "            \n",
    "            block = np.expand_dims(LR[x:x + batchsize,\n",
    "                                      y:y + cropsize,\n",
    "                                      z:z + cropsize], axis=3)\n",
    "            \n",
    "            blockHR = np.expand_dims(HR[x * scale : x * scale + batchsize * scale,\n",
    "                                        y * scale : y * scale + cropsize * scale,\n",
    "                                        z * scale : z * scale + cropsize * scale], axis=3)\n",
    "\n",
    "        elif np.mod(i, 3) == 1:\n",
    "            # YZ-style block:\n",
    "            #    block shape:    [batchsize, cropsize, cropsize, 1] (after transpose)\n",
    "            #    blockHR shape: [batchsize*scale, cropsize*scale, cropsize*scale, 1]\n",
    "            x = int(np.floor(np.random.rand() * (LR.shape[0] - cropsize)))\n",
    "            y = int(np.floor(np.random.rand() * (LR.shape[1] - cropsize)))\n",
    "            z = int(np.floor(np.random.rand() * (LR.shape[2] - batchsize)))\n",
    "            \n",
    "            block = np.expand_dims(LR[x:x + cropsize,\n",
    "                                      y:y + cropsize,\n",
    "                                      z:z + batchsize], axis=3)\n",
    "            \n",
    "            blockHR = np.expand_dims(HR[x * scale : x * scale + cropsize * scale,\n",
    "                                         y * scale : y * scale + cropsize * scale,\n",
    "                                         z * scale : z * scale + batchsize * scale], axis=3)\n",
    "            \n",
    "            # Transpose so that the batch dimension is first\n",
    "            block = np.transpose(block,   [2, 0, 1, 3])   # shape → [batchsize, cropsize, cropsize, 1]\n",
    "            blockHR = np.transpose(blockHR, [2, 0, 1, 3]) # shape → [batchsize*scale, cropsize*scale, cropsize*scale, 1]\n",
    "\n",
    "        elif np.mod(i, 3) == 2:\n",
    "            # XZ-style block:\n",
    "            #    block shape:    [batchsize, cropsize, cropsize, 1] (after transpose)\n",
    "            #    blockHR shape: [batchsize*scale, cropsize*scale, cropsize*scale, 1]\n",
    "            x = int(np.floor(np.random.rand() * (LR.shape[0] - cropsize)))\n",
    "            y = int(np.floor(np.random.rand() * (LR.shape[1] - batchsize)))\n",
    "            z = int(np.floor(np.random.rand() * (LR.shape[2] - cropsize)))\n",
    "            \n",
    "            block = np.expand_dims(LR[x:x + cropsize,\n",
    "                                      y:y + batchsize,\n",
    "                                      z:z + cropsize], axis=3)\n",
    "            \n",
    "            blockHR = np.expand_dims(HR[x * scale : x * scale + cropsize * scale,\n",
    "                                         y * scale : y * scale + batchsize * scale,\n",
    "                                         z * scale : z * scale + cropsize * scale], axis=3)\n",
    "            \n",
    "            # Transpose so that the batch dimension is first\n",
    "            block = np.transpose(block,   [1, 0, 2, 3])   # shape → [batchsize, cropsize, cropsize, 1]\n",
    "            blockHR = np.transpose(blockHR, [1, 0, 2, 3]) # shape → [batchsize*scale, cropsize*scale, cropsize*scale, 1]\n",
    "        \n",
    "        # Write these blocks into batchLR / batchHR\n",
    "        batchLR[n : n + batchsize] = block / 127.5 - 1.0\n",
    "        batchHR[n2 : n2 + batchsize * scale] = blockHR / 127.5 - 1.0\n",
    "        \n",
    "        n  += batchsize\n",
    "        n2 += batchsize * scale\n",
    "\n",
    "    return batchHR, batchLR\n",
    "\n",
    "def test_memory_efficient_3d(test_files: List[str], \n",
    "                          generator_sr: nn.Module, \n",
    "                          generator_src: nn.Module,\n",
    "                          args, device):\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(os.path.join(args.test_save_dir, args.modelName)):\n",
    "        os.makedirs(os.path.join(args.test_save_dir, args.modelName), exist_ok=True)\n",
    "    \n",
    "    # Step 1: XY super-resolution for all slices\n",
    "    print(\"Starting XY super-resolution pass...\")\n",
    "    xy_processed_slices = []\n",
    "    \n",
    "    # Use tqdm for processing slices\n",
    "    for i, file_path in tqdm(enumerate(test_files), total=len(test_files), desc=\"XY Pass\"):\n",
    "        # Load image\n",
    "        slice_z = imageio.imread(file_path)\n",
    "        slice_z = (slice_z / 127.5) - 1  # Normalize to [-1, 1]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        slice_z = torch.tensor(slice_z, dtype=torch.float32)\n",
    "        slice_z = slice_z.unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "        slice_z = slice_z.to(device)\n",
    "        \n",
    "        # Process through first SR network in chunks if needed\n",
    "        with torch.no_grad():\n",
    "            xy_result = process_image_in_chunks(generator_sr, slice_z, args, device, 'xy')\n",
    "            \n",
    "            # Quantize to 8-bit\n",
    "            xy_result = (xy_result + 1) * 127.5\n",
    "            xy_result = torch.round(xy_result).clamp(0, 255).to(torch.uint8)\n",
    "            xy_result = xy_result / 127.5 - 1\n",
    "            \n",
    "            # Store result\n",
    "            xy_processed_slices.append(xy_result.squeeze(0).squeeze(0).cpu().numpy())\n",
    "    \n",
    "    # Get output dimensions\n",
    "    out_height = xy_processed_slices[0].shape[0]\n",
    "    out_width = xy_processed_slices[0].shape[1]\n",
    "    num_slices = len(xy_processed_slices)\n",
    "    \n",
    "    # Create output volume for storing results\n",
    "    output_volume = np.zeros((num_slices * args.scale, out_height, out_width), dtype=np.uint8)\n",
    "    \n",
    "    # Step 2: YZ super-resolution\n",
    "    print(\"Starting YZ super-resolution pass...\")\n",
    "    \n",
    "    # Process in batches to manage memory\n",
    "    batch_size = min(50, out_width)  # Process 50 vertical slices at once\n",
    "    \n",
    "    # Use tqdm for the y batches\n",
    "    for y_start in tqdm(range(0, out_height, batch_size), desc=\"YZ Pass\"):\n",
    "        y_end = min(y_start + batch_size, out_height)\n",
    "        \n",
    "        # Extract batch of vertical slices\n",
    "        vertical_slices_batch = []\n",
    "        for y in range(y_start, y_end):\n",
    "            # Extract vertical slice from all XY-processed slices for this row\n",
    "            vertical_slice = np.stack([slice_data[y, :] for slice_data in xy_processed_slices])\n",
    "            vertical_slices_batch.append(vertical_slice)\n",
    "        \n",
    "        # Stack slices into a batch - [B, Z, X] where B is the batch of Y positions\n",
    "        vertical_batch = np.stack(vertical_slices_batch, axis=0)  \n",
    "        vertical_batch_tensor = torch.tensor(vertical_batch, dtype=torch.float32)\n",
    "        vertical_batch_tensor = vertical_batch_tensor.unsqueeze(1)  # Add channel dimension [B, C, Z, X]\n",
    "        vertical_batch_tensor = vertical_batch_tensor.to(device)\n",
    "        \n",
    "        # Process through YZ SR network\n",
    "        with torch.no_grad():\n",
    "            # Process each slice in the batch individually to avoid size mismatch\n",
    "            processed_slices = []\n",
    "            for b in range(vertical_batch_tensor.size(0)):\n",
    "                # Extract single slice [1, 1, Z, X]\n",
    "                single_slice = vertical_batch_tensor[b:b+1]\n",
    "                \n",
    "                # Process this slice\n",
    "                processed_slice = process_image_in_chunks(\n",
    "                    generator_src, \n",
    "                    single_slice, \n",
    "                    args, \n",
    "                    device,\n",
    "                    'yz'\n",
    "                )\n",
    "                processed_slices.append(processed_slice)\n",
    "            \n",
    "            # Concatenate results [B, C, Z*scale, X]\n",
    "            processed_batch = torch.cat(processed_slices, dim=0)\n",
    "            \n",
    "            # Get output as numpy array and normalize to [0, 255]\n",
    "            processed_batch = (processed_batch.cpu().numpy() + 1) * 127.5\n",
    "            processed_batch = np.round(processed_batch).astype(np.uint8)\n",
    "            \n",
    "            # Insert results into output volume\n",
    "            for i, y in enumerate(range(y_start, y_end)):\n",
    "                output_volume[:, y, :] = processed_batch[i, 0]\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # Save full 3D volume\n",
    "    output_path = f'{args.test_save_dir}/{args.modelName}/full_volume.tif'\n",
    "    print(f\"Saving complete 3D volume with shape [D={output_volume.shape[0]}, H={output_volume.shape[1]}, W={output_volume.shape[2]}] to {output_path}\")\n",
    "    tifffile.imwrite(output_path, output_volume)\n",
    "    \n",
    "    return output_volume\n",
    "\n",
    "def process_entire_volume(test_files: List[str], \n",
    "                          generator_sr: nn.Module, \n",
    "                          generator_src: nn.Module,\n",
    "                          args, device):\n",
    "    \"\"\"\n",
    "    Process 3D volumes without chunking when sufficient memory is available\n",
    "    \n",
    "    Args:\n",
    "        test_files: List of image file paths to process\n",
    "        generator_sr: XY plane super-resolution model\n",
    "        generator_src: YZ plane super-resolution model\n",
    "        args: Configuration arguments\n",
    "        device: Computation device (CPU/GPU)\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(os.path.join(args.test_save_dir, args.modelName)):\n",
    "        os.makedirs(os.path.join(args.test_save_dir, args.modelName), exist_ok=True)\n",
    "    \n",
    "    # Step 1: XY super-resolution for all slices\n",
    "    print(\"Starting XY super-resolution pass...\")\n",
    "    \n",
    "    # Load all XY slices at once\n",
    "    slices_z = []\n",
    "    for i, file_path in tqdm(enumerate(test_files), total=len(test_files), desc=\"Loading XY slices\"):\n",
    "        slice_z = imageio.imread(file_path)\n",
    "        slices_z.append(slice_z)\n",
    "    \n",
    "    # Stack all slices into a single volume [Z, H, W]\n",
    "    xy_volume = np.stack(slices_z, axis=0)\n",
    "    print(f\"Loaded volume shape: {xy_volume.shape}\")\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    xy_volume_norm = (xy_volume / 127.5) - 1\n",
    "    \n",
    "    # Split into smaller batches for GPU processing (based on GPU memory)\n",
    "    # but process all at once on CPU if needed\n",
    "    batch_size = 32 if torch.cuda.is_available() else len(xy_volume_norm)\n",
    "    xy_processed_slices = []\n",
    "    \n",
    "    print(\"Processing XY slices...\")\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(xy_volume_norm), batch_size), desc=\"XY Pass\"):\n",
    "            # Get batch of slices\n",
    "            batch_slices = xy_volume_norm[i:i+batch_size]\n",
    "            \n",
    "            # Convert to tensor [B, 1, H, W]\n",
    "            batch_tensor = torch.tensor(batch_slices, dtype=torch.float32).unsqueeze(1)\n",
    "            batch_tensor = batch_tensor.to(device)\n",
    "            \n",
    "            # Process through SR network\n",
    "            xy_result = generator_sr(batch_tensor)\n",
    "            \n",
    "            # Move result to CPU before quantization\n",
    "            xy_result = xy_result.cpu()\n",
    "            \n",
    "            # Store results\n",
    "            for j in range(xy_result.shape[0]):\n",
    "                xy_processed_slices.append(xy_result[j, 0].numpy())\n",
    "    \n",
    "    # Get output dimensions\n",
    "    out_height = xy_processed_slices[0].shape[0]\n",
    "    out_width = xy_processed_slices[0].shape[1]\n",
    "    num_slices = len(xy_processed_slices)\n",
    "    \n",
    "    # Stack into a volume [Z, H, W]\n",
    "    xy_volume_sr = np.stack(xy_processed_slices, axis=0)\n",
    "    \n",
    "    # Quantize to 8-bit representation (between -1 and 1)\n",
    "    xy_volume_sr = np.round((xy_volume_sr + 1) * 127.5) / 127.5 - 1\n",
    "    \n",
    "    # Create output volume for final results\n",
    "    output_volume = np.zeros((num_slices * args.scale, out_height, out_width), dtype=np.uint8)\n",
    "    \n",
    "    # Step 2: YZ super-resolution - process entire volume at once\n",
    "    print(\"Starting YZ super-resolution pass...\")\n",
    "    print(f\"XY super-resolved volume shape: {xy_volume_sr.shape}\")\n",
    "    \n",
    "    # Process entire volume row by row along Y dimension\n",
    "    with torch.no_grad():\n",
    "        for y in tqdm(range(out_height), desc=\"YZ Pass\"):\n",
    "            # Extract vertical slice from all XY-processed slices for this row [Z, W]\n",
    "            vertical_slice = xy_volume_sr[:, y, :]\n",
    "            \n",
    "            # Prepare for model - add batch and channel dimensions [1, 1, Z, W]\n",
    "            vertical_tensor = torch.tensor(vertical_slice, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "            vertical_tensor = vertical_tensor.to(device)\n",
    "            \n",
    "            # Process through YZ SR network\n",
    "            vertical_sr = generator_src(vertical_tensor)\n",
    "            \n",
    "            # Get output and convert to uint8\n",
    "            vertical_sr_np = (vertical_sr.cpu().numpy() + 1) * 127.5\n",
    "            vertical_sr_np = np.round(vertical_sr_np).astype(np.uint8)\n",
    "            \n",
    "            # Insert into output volume\n",
    "            output_volume[:, y, :] = vertical_sr_np[0, 0]\n",
    "            \n",
    "            # Clear GPU memory if needed\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save full 3D volume\n",
    "    output_path = f'{args.test_save_dir}/{args.modelName}/full_volume_direct.tif'\n",
    "    print(f\"Saving complete 3D volume with shape [D={output_volume.shape[0]}, H={output_volume.shape[1]}, W={output_volume.shape[2]}] to {output_path}\")\n",
    "    tifffile.imwrite(output_path, output_volume)\n",
    "    \n",
    "    return output_volume\n",
    "\n",
    "def quantize(x):\n",
    "    x = (x + 1) * 127.5\n",
    "    x = StraightThroughRound.apply(x)\n",
    "    x = torch.clamp(x, 0, 255)\n",
    "    return x / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7428accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define arguments\n",
    "    args = Args()\n",
    "\n",
    "    # Create checkpoint directory\n",
    "    training_dir = f\"{args.checkpoint_dir}/{args.modelName}\"\n",
    "    if not os.path.exists(training_dir):\n",
    "        os.makedirs(training_dir, exist_ok=True)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(f'cuda:{args.gpuIDs}' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize models\n",
    "    generator_sr = EDSR(scale=args.scale, num_filters=args.ngsrf, num_res_blocks=args.numResBlocks, ndims=2)\n",
    "    generator_src = EDSR1D(scale=args.scale, num_filters=args.ngsrf//2, num_res_blocks=args.numResBlocks//2, ndims=2)\n",
    "    \n",
    "    # Move models to device\n",
    "    generator_sr = generator_sr.to(device)\n",
    "    generator_src = generator_src.to(device)\n",
    "    \n",
    "    # Initialize optimizers\n",
    "    optimizer_gen_sr = optim.Adam(generator_sr.parameters(), lr=args.lr)\n",
    "    optimizer_gen_src = optim.Adam(generator_src.parameters(), lr=args.lr)\n",
    "    \n",
    "    # Initialize CosineAnnealingWarmRestarts scheduler\n",
    "    scheduler_gen_sr = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer_gen_sr,\n",
    "        T_0=args.epoch_step,  # Initial restart interval\n",
    "        T_mult=2,  # Increase T_0 by this factor after each restart\n",
    "        eta_min=args.eta_min  # Minimum learning rate\n",
    "    )\n",
    "\n",
    "    scheduler_gen_src = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer_gen_src,\n",
    "        T_0=args.epoch_step,  # Initial restart interval\n",
    "        T_mult=2,  # Increase T_0 by this factor after each restart\n",
    "        eta_min=args.eta_min  # Minimum learning rate\n",
    "    )\n",
    "    \n",
    "    # Load checkpoints for testing or continuing training\n",
    "    if args.phase == 'test':\n",
    "        print(f'Loading checkpoints from {training_dir}')\n",
    "        try:\n",
    "            # Try to load the best model first if specified\n",
    "            if args.use_best_model:\n",
    "                best_model_path = f'{training_dir}/GSR-best.pth'\n",
    "                if os.path.exists(best_model_path):\n",
    "                    print(f\"Loading best model from {best_model_path}\")\n",
    "                    generator_sr.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "                    generator_src.load_state_dict(torch.load(f'{training_dir}/GSRC-best.pth', map_location=device))\n",
    "                    print(\"Successfully loaded best models\")\n",
    "                else:\n",
    "                    # Fall back to specified epoch\n",
    "                    print(f\"Best model not found, loading epoch {args.continueEpoch}\")\n",
    "                    generator_sr.load_state_dict(torch.load(f'{training_dir}/GSR-{args.continueEpoch}.pth', map_location=device))\n",
    "                    generator_src.load_state_dict(torch.load(f'{training_dir}/GSRC-{args.continueEpoch}.pth', map_location=device))\n",
    "                    print(f\"Successfully loaded models from epoch {args.continueEpoch}\")\n",
    "            else:\n",
    "                # Load specified epoch directly\n",
    "                generator_sr.load_state_dict(torch.load(f'{training_dir}/GSR-{args.continueEpoch}.pth', map_location=device))\n",
    "                generator_src.load_state_dict(torch.load(f'{training_dir}/GSRC-{args.continueEpoch}.pth', map_location=device))\n",
    "                print(f\"Successfully loaded models from epoch {args.continueEpoch}\")\n",
    "        except Exception as e:\n",
    "            print(f'Could not load SR related weights: {str(e)}')\n",
    "            print('Will start with fresh weights')\n",
    "    elif args.continue_train:\n",
    "        print(f'Loading checkpoints from {training_dir} for epoch {args.continueEpoch}')\n",
    "        try:\n",
    "            # Load model weights\n",
    "            generator_sr.load_state_dict(torch.load(f'{training_dir}/GSR-{args.continueEpoch}.pth', map_location=device))\n",
    "            generator_src.load_state_dict(torch.load(f'{training_dir}/GSRC-{args.continueEpoch}.pth', map_location=device))\n",
    "            \n",
    "            # Try to load optimizer state if available\n",
    "            try:\n",
    "                gen_sr_checkpoint = torch.load(f'{training_dir}/GSR-{args.continueEpoch}_full.pth', map_location=device)\n",
    "                gen_src_checkpoint = torch.load(f'{training_dir}/GSRC-{args.continueEpoch}_full.pth', map_location=device)\n",
    "                \n",
    "                optimizer_gen_sr.load_state_dict(gen_sr_checkpoint['optimizer_state_dict'])\n",
    "                optimizer_gen_src.load_state_dict(gen_src_checkpoint['optimizer_state_dict'])\n",
    "                print(\"Successfully loaded optimizers\")\n",
    "                \n",
    "                # Fast-forward scheduler to current epoch\n",
    "                for _ in range(args.continueEpoch):\n",
    "                    scheduler_gen_sr.step()\n",
    "                    scheduler_gen_src.step()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Could not load optimizer states: {str(e)}\")\n",
    "                print(\"Will use fresh optimizers\")\n",
    "                \n",
    "            print(\"Successfully loaded model weights\")\n",
    "        except Exception as e:\n",
    "            print(f'Could not load SR related weights: {str(e)}')\n",
    "            print('Will start with fresh weights')\n",
    "    \n",
    "    # Training phase\n",
    "    if args.phase == 'train':\n",
    "        # Create output directories\n",
    "        right_now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        val_out_dir = args.dataset_dir.split('/')[-1] if '/' in args.dataset_dir else args.dataset_dir.split('\\\\\\\\')[-1]\n",
    "        train_output_dir = f'./training_outputs/{right_now}-pytorch-{val_out_dir}-{args.modelName}/'\n",
    "        os.makedirs(train_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Authenticate with wandb before initializing\n",
    "        if not authenticate_wandb(args.wandb_api_key, args.wandb_entity):\n",
    "            print(\"Warning: wandb authentication failed. Continuing without experiment tracking.\")\n",
    "        \n",
    "        # Initialize wandb for tracking\n",
    "        wandb.init(\n",
    "            project=args.wandb_project,\n",
    "            entity=args.wandb_entity,\n",
    "            name=f\"{args.modelName}-{right_now}\",\n",
    "            config={\n",
    "                \"model\": args.modelName,\n",
    "                \"scale\": args.scale,\n",
    "                \"learning_rate\": args.lr,\n",
    "                \"epochs\": args.epoch,\n",
    "                \"batch_size\": args.batch_size,\n",
    "                \"patch_size\": args.patch_size,\n",
    "                \"num_res_blocks\": args.numResBlocks,\n",
    "                \"filters_sr\": args.ngsrf,\n",
    "                \"filters_src\": args.ngsrf//2,\n",
    "                \"dataset\": val_out_dir,\n",
    "                \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "                \"scheduler_T0\": args.epoch_step,\n",
    "                \"scheduler_T_mult\": 2,\n",
    "                \"scheduler_eta_min\": args.eta_min\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Log model architecture as a string\n",
    "        wandb.run.summary[\"model_sr\"] = str(generator_sr)\n",
    "        wandb.run.summary[\"model_src\"] = str(generator_src)\n",
    "\n",
    "        # Initialize metric tracking\n",
    "        train_losses = {\n",
    "            'epoch': [],\n",
    "            'sr_xy_loss': [],\n",
    "            'sr_yz_loss': [],\n",
    "            'total_loss': [],\n",
    "            'global_step': []\n",
    "        }\n",
    "\n",
    "        val_metrics = {\n",
    "            'epoch': [],\n",
    "            'psnr_xy': [],\n",
    "            'psnr_xyz': [],\n",
    "            'l1_loss': [],\n",
    "            'global_step': []\n",
    "        }\n",
    "        \n",
    "        # Initialize batch-level losses for more detailed tracking\n",
    "        batch_losses = []\n",
    "        \n",
    "        # Initialize best model tracking\n",
    "        best_model = {\n",
    "            'epoch': 0,\n",
    "            'val_psnr_xyz': 0.0,\n",
    "            'val_psnr_xy': 0.0,\n",
    "            'val_l1_loss': float('inf')\n",
    "        }\n",
    "\n",
    "        print('2D/3D training specified, datasets will be randomly mini-batched per epoch')\n",
    "        print('2D/3D dataset and training -> data will be fully preloaded into RAM')\n",
    "        \n",
    "        # Load training data\n",
    "        BC_loc = glob(os.path.join(args.dataset_dir, 'LR.npy'))\n",
    "        if not BC_loc:\n",
    "            raise FileNotFoundError(f\"LR.npy not found in {args.dataset_dir}\")\n",
    "        print(f\"Loading LR data from: {BC_loc[0]}\")\n",
    "        LR = np.load(BC_loc[0])\n",
    "        \n",
    "        HR_loc = glob(os.path.join(args.dataset_dir, 'HR.npy'))\n",
    "        if not HR_loc:\n",
    "            raise FileNotFoundError(f\"HR.npy not found in {args.dataset_dir}\")\n",
    "        print(f\"Loading HR data from: {HR_loc[0]}\")\n",
    "        HR = np.load(HR_loc[0])\n",
    "        \n",
    "        print(f\"LR shape: {LR.shape}, HR shape: {HR.shape}\")\n",
    "        wandb.run.summary[\"dataset_lr_shape\"] = str(LR.shape)\n",
    "        wandb.run.summary[\"dataset_hr_shape\"] = str(HR.shape)\n",
    "        \n",
    "        # Load test data if needed\n",
    "        if args.valTest:\n",
    "            LR_test_loc = glob(os.path.join(args.dataset_dir, 'test', '*'))\n",
    "            if not LR_test_loc:\n",
    "                print(f\"Warning: No test data found in {os.path.join(args.dataset_dir, 'test')}\")\n",
    "            else:\n",
    "                LR_test = np.load(LR_test_loc[0])\n",
    "                LR_test = torch.tensor(LR_test, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "                LR_test = LR_test.to(device)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        global_step = 0  # For wandb step tracking\n",
    "        \n",
    "        for epoch in range(args.epoch):\n",
    "            # Adjust batch and crop size\n",
    "            total_per_batch_voxels = args.patch_size * args.patch_size * args.batch_size\n",
    "            min_per_dim_size = args.batch_size\n",
    "            max_per_dim_size = args.patch_size\n",
    "            batch_size_this_epoch = int(np.floor(np.random.rand()*(max_per_dim_size-min_per_dim_size))+min_per_dim_size)\n",
    "            patch_size_this_epoch = int(np.floor(np.sqrt(total_per_batch_voxels/batch_size_this_epoch)))\n",
    "            \n",
    "            print(f'Reading dataset, block size this epoch: {batch_size_this_epoch} x {patch_size_this_epoch} x {patch_size_this_epoch} -> {args.scale}x')\n",
    "            \n",
    "            # Create training data batches\n",
    "            real_HR_batches, real_BC_batches = createTrainingCubes2(args, HR, LR, batch_size_this_epoch, patch_size_this_epoch, args.scale)\n",
    "            \n",
    "            # Convert to PyTorch tensors\n",
    "            HR_dataset = torch.from_numpy(real_HR_batches).permute(0, 3, 1, 2).float()  # [B, C, H, W]\n",
    "            LR_dataset = torch.from_numpy(real_BC_batches).permute(0, 3, 1, 2).float()  # [B, C, H, W]\n",
    "            \n",
    "            # Create validation subset\n",
    "            HR_val_dataset = HR_dataset[:args.valNum*batch_size_this_epoch*args.scale]\n",
    "            LR_val_dataset = LR_dataset[:args.valNum*batch_size_this_epoch]\n",
    "\n",
    "            # Prepare data loaders\n",
    "            train_dataset = DualSRDataset(HR_dataset, LR_dataset, args.scale)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size_this_epoch,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "            # Get learning rate\n",
    "            current_lr = optimizer_gen_sr.param_groups[0]['lr']\n",
    "            print(f'Learning Rate: {current_lr:.6e}')\n",
    "\n",
    "            # Log learning rate to wandb\n",
    "            wandb.log({\n",
    "                \"learning_rate\": current_lr,\n",
    "                \"epoch\": epoch+1\n",
    "            }, step=global_step)\n",
    "            \n",
    "            # Training loop variables\n",
    "            tot_g_sr_xy_loss = 0\n",
    "            tot_g_sr_yz_loss = 0\n",
    "            num_batches = 0\n",
    "            last_time = time.time()\n",
    "            \n",
    "            # Set models to training mode\n",
    "            generator_sr.train()\n",
    "            generator_src.train()\n",
    "            \n",
    "            # Iterator for cycling through data multiple times if needed\n",
    "            train_iter = iter(train_loader)\n",
    "            \n",
    "            # Main training loop\n",
    "            pbar = tqdm(total=args.itersPerEpoch * args.iterCyclesPerEpoch, desc=f\"Epoch {epoch+1}/{args.epoch}\")\n",
    "            \n",
    "            while num_batches < args.itersPerEpoch * args.iterCyclesPerEpoch:\n",
    "                # Get next batch or reset iterator\n",
    "                try:\n",
    "                    B_xy, C_xyz_group = next(train_iter)\n",
    "                except StopIteration:\n",
    "                    train_iter = iter(train_loader)\n",
    "                    B_xy, C_xyz_group = next(train_iter)\n",
    "\n",
    "                # Move data to device\n",
    "                B_xy = move_to_device(B_xy, device)\n",
    "                C_xyz_group = move_to_device(C_xyz_group, device)\n",
    "                \n",
    "                # Data augmentation if enabled\n",
    "                if args.augFlag:\n",
    "                    B_xy = augment_data(B_xy)\n",
    "                \n",
    "                # Zero gradients\n",
    "                optimizer_gen_sr.zero_grad()\n",
    "                optimizer_gen_src.zero_grad()\n",
    "                \n",
    "                # Take the first HR slice (from the group) for XY model\n",
    "                # We can reshape the batch dimension to match what C_xyz_downsampled expects\n",
    "                C_xyz = C_xyz_group.view(-1, C_xyz_group.size(2), C_xyz_group.size(3), C_xyz_group.size(4))\n",
    "                C_xy_downsampled = F.interpolate(C_xyz.permute(1, 2, 0, 3), size=(C_xyz.size(0)//args.scale, C_xyz.size(2)), mode='bicubic', align_corners=False)\n",
    "                C_xy_downsampled = C_xy_downsampled.permute(2, 0, 1, 3)\n",
    "                \n",
    "                # Forward pass XY SR\n",
    "                SR_xy = generator_sr(B_xy)\n",
    "                loss_sr_xy = F.l1_loss(SR_xy, C_xy_downsampled)\n",
    "\n",
    "                # Quantize to 8-bit\n",
    "                SR_xy_quantized = quantize(SR_xy)\n",
    "                \n",
    "                # SR_xy has shape [B, C, H, W]\n",
    "                SR_xy_t = SR_xy_quantized.permute(2, 1, 0, 3).to(device)  # [H, C, B, W]\n",
    "                \n",
    "                # Forward pass YZ SR\n",
    "                SR_xyz = generator_src(SR_xy_t)\n",
    "                C_xyz_t = C_xyz.permute(2, 1, 0, 3)  # [H, C, B, W]\n",
    "                loss_sr_yz = F.l1_loss(SR_xyz, C_xyz_t)\n",
    "                \n",
    "                # Combined loss\n",
    "                total_loss = loss_sr_xy + loss_sr_yz\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # Update parameters\n",
    "                optimizer_gen_sr.step()\n",
    "                optimizer_gen_src.step()\n",
    "                \n",
    "                # Get loss values\n",
    "                loss_sr_xy_val = loss_sr_xy.item()\n",
    "                loss_sr_yz_val = loss_sr_yz.item()\n",
    "                \n",
    "                # Update counters and stats\n",
    "                tot_g_sr_xy_loss += loss_sr_xy_val\n",
    "                tot_g_sr_yz_loss += loss_sr_yz_val\n",
    "                num_batches += 1\n",
    "                global_step += 1\n",
    "                \n",
    "                # Store batch-level losses\n",
    "                batch_losses.append({\n",
    "                    'epoch': epoch+1,\n",
    "                    'batch': num_batches,\n",
    "                    'sr_xy_loss': loss_sr_xy_val,\n",
    "                    'sr_yz_loss': loss_sr_yz_val,\n",
    "                    'total_loss': loss_sr_xy_val + loss_sr_yz_val,\n",
    "                    'global_step': global_step,\n",
    "                    'lr': current_lr\n",
    "                })\n",
    "                \n",
    "                # Log metrics to wandb every 10 batches\n",
    "                if num_batches % 10 == 0:\n",
    "                    wandb.log({\n",
    "                        \"train/sr_xy_loss\": loss_sr_xy_val,\n",
    "                        \"train/sr_yz_loss\": loss_sr_yz_val,\n",
    "                        \"train/total_loss\": loss_sr_xy_val + loss_sr_yz_val,\n",
    "                        \"train/iteration_time\": time.time() - last_time,\n",
    "                        \"train/iterations_per_second\": 1.0 / (time.time() - last_time if time.time() > last_time else 1e-5),\n",
    "                    }, step=global_step)\n",
    "                \n",
    "                current_time = time.time()\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'Time': f\"{current_time-start_time:.2f}s\", \n",
    "                    'Speed': f\"{1/(current_time-last_time if current_time > last_time else 1e-5):.2f} it/s\", \n",
    "                    'GSRxyL': f\"{loss_sr_xy_val:.4f}\", \n",
    "                    'GSRyzL': f\"{loss_sr_yz_val:.4f}\"\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                \n",
    "                last_time = current_time\n",
    "                \n",
    "                # Break if reached target iterations\n",
    "                if num_batches >= args.itersPerEpoch * args.iterCyclesPerEpoch:\n",
    "                    break\n",
    "\n",
    "            pbar.close()\n",
    "            \n",
    "            # Calculate epoch statistics\n",
    "            tot_g_sr_xy_loss /= num_batches\n",
    "            tot_g_sr_yz_loss /= num_batches\n",
    "            print(f'Mean Epoch Performance: GSRxyL: {tot_g_sr_xy_loss:.4f}, GSRyzL: {tot_g_sr_yz_loss:.4f}')\n",
    "            \n",
    "            # Update epoch-level metrics\n",
    "            train_losses['epoch'].append(epoch+1)\n",
    "            train_losses['sr_xy_loss'].append(tot_g_sr_xy_loss)\n",
    "            train_losses['sr_yz_loss'].append(tot_g_sr_yz_loss)\n",
    "            train_losses['total_loss'].append(tot_g_sr_xy_loss + tot_g_sr_yz_loss)\n",
    "            train_losses['global_step'].append(global_step)\n",
    "            \n",
    "            # Log epoch statistics to wandb\n",
    "            wandb.log({\n",
    "                \"epoch/sr_xy_loss\": tot_g_sr_xy_loss,\n",
    "                \"epoch/sr_yz_loss\": tot_g_sr_yz_loss,\n",
    "                \"epoch/total_loss\": tot_g_sr_xy_loss + tot_g_sr_yz_loss,\n",
    "                \"epoch\": epoch+1\n",
    "            }, step=global_step)\n",
    "            \n",
    "            # Validation and visualization\n",
    "            if np.mod(epoch+1, args.print_freq) == 0 or epoch == 0:\n",
    "                # Create epoch output directory\n",
    "                \n",
    "                \n",
    "                # Set models to evaluation mode\n",
    "                generator_sr.eval()\n",
    "                generator_src.eval()\n",
    "                \n",
    "                val_psnr_xy = 0.0\n",
    "                val_psnr_xyz = 0.0\n",
    "                val_l1_loss_total = 0.0\n",
    "                num_test_batches = 0\n",
    "                \n",
    "\n",
    "                # Validation loop\n",
    "                val_pbar = tqdm(total=args.valNum, desc=\"Validation\")\n",
    "                with torch.no_grad():\n",
    "                    for i in range(0, len(HR_val_dataset), batch_size_this_epoch):\n",
    "                        if i + batch_size_this_epoch > len(HR_val_dataset):\n",
    "                            break\n",
    "                            \n",
    "                        # Create a validation subset with proper structure\n",
    "                        val_lr = LR_val_dataset[i:i+batch_size_this_epoch].to(device)\n",
    "                        val_hr_start = i * args.scale\n",
    "                        val_hr_end = val_hr_start + batch_size_this_epoch * args.scale\n",
    "                        val_hr = HR_val_dataset[val_hr_start:val_hr_end].to(device)\n",
    "\n",
    "                        # Reshape val_hr to match our dataset format [B, C, H, W]\n",
    "                        val_hr_downsampled = F.interpolate(val_hr.permute(1, 2, 0, 3), size=(val_hr.size(0)//args.scale, val_hr.size(2)), mode='bicubic', align_corners=False)\n",
    "                        val_hr_downsampled = val_hr_downsampled.permute(2, 0, 1, 3)\n",
    "                        \n",
    "                        # Forward pass XY\n",
    "                        generated_xy = generator_sr(val_lr)\n",
    "                        \n",
    "                        # Calculate PSNR\n",
    "                        psnr_xy = calculate_psnr(generated_xy, val_hr_downsampled)\n",
    "                        \n",
    "                        # Store results on CPU after calculation\n",
    "                        generated_xy_output = generated_xy.detach().cpu().numpy()\n",
    "\n",
    "                        # Quantize to 8-bit\n",
    "                        generated_xy = (generated_xy + 1) * 127.5\n",
    "                        generated_xy = torch.round(generated_xy).clamp(0, 255).to(torch.uint8)\n",
    "                        generated_xy = generated_xy / 127.5 - 1\n",
    "\n",
    "                        # Transpose for YZ dimension (ensure on device)\n",
    "                        generated_xy_t = generated_xy.permute(2, 1, 0, 3).to(device)\n",
    "                        \n",
    "\n",
    "                        # Forward pass YZ\n",
    "                        generated_xyz = generator_src(generated_xy_t)\n",
    "                        generated_xyz = generated_xyz.permute(2, 1, 0, 3)\n",
    "                        psnr_xyz = calculate_psnr(generated_xyz, val_hr)\n",
    "                        generated_xyz_output = generated_xyz.detach().cpu().numpy()\n",
    "                        \n",
    "                        # Calculate L1 loss explicitly\n",
    "                        batch_l1_loss = F.l1_loss(generated_xyz, val_hr).item()\n",
    "                        \n",
    "                        # Update statistics\n",
    "                        val_psnr_xy += psnr_xy.item()\n",
    "                        val_psnr_xyz += psnr_xyz.item()\n",
    "                        val_l1_loss_total += batch_l1_loss\n",
    "                        num_test_batches += 1\n",
    "                        \n",
    "                        val_lr_np = (val_lr.detach().cpu().numpy() + 1) * 127.5\n",
    "                        val_hr_np = (val_hr.detach().cpu().numpy() + 1) * 127.5\n",
    "                        val_hr_downsampled_np = (val_hr_downsampled.detach().cpu().numpy() + 1) * 127.5\n",
    "                        generated_xy_np = (generated_xy_output + 1) * 127.5\n",
    "                        generated_xyz_np = (generated_xyz_output + 1) * 127.5\n",
    "                        \n",
    "                        # Save images periodically\n",
    "                        if np.mod(epoch+1, args.save_freq) == 0 or epoch == args.epoch - 1:\n",
    "                            os.makedirs(f'./{train_output_dir}/epoch-{epoch+1}/', exist_ok=True)\n",
    "                            \n",
    "                            image_path = f'./{train_output_dir}/epoch-{epoch+1}/{num_test_batches}-LRxyz.tif'\n",
    "                            tifffile.imwrite(image_path, np.squeeze(val_lr_np.astype('uint8')))\n",
    "\n",
    "                            image_path = f'./{train_output_dir}/epoch-{epoch+1}/{num_test_batches}-HRxyz.tif'\n",
    "                            tifffile.imwrite(image_path, np.squeeze(val_hr_np.astype('uint8')))\n",
    "\n",
    "                            image_path = f'./{train_output_dir}/epoch-{epoch+1}/{num_test_batches}-HRxyz-downsampled.tif'\n",
    "                            tifffile.imwrite(image_path, np.squeeze(val_hr_downsampled_np.astype('uint8')))\n",
    "\n",
    "                            image_path = f'./{train_output_dir}/epoch-{epoch+1}/{num_test_batches}-SRxy.tif'\n",
    "                            tifffile.imwrite(image_path, np.squeeze(generated_xy_np.astype('uint8')))\n",
    "\n",
    "                            image_path = f'./{train_output_dir}/epoch-{epoch+1}/{num_test_batches}-SRxyz.tif'\n",
    "                            tifffile.imwrite(image_path, np.squeeze(generated_xyz_np.astype('uint8')))\n",
    "                        \n",
    "                        # Log images to wandb (just first batch)\n",
    "                        if num_test_batches == 1:\n",
    "                            # Log sample images to wandb\n",
    "                            wandb.log({\n",
    "                                \"images/lr\": wandb.Image(np.squeeze(val_lr_np[0].astype(np.uint8)), \n",
    "                                                      caption=\"Low Resolution\"),\n",
    "                                \"images/hr\": wandb.Image(np.squeeze(val_hr_np[0].astype(np.uint8)), \n",
    "                                                       caption=\"High Resolution\"),\n",
    "                                \"images/hr_downsampled\": wandb.Image(np.squeeze(val_hr_downsampled_np[0].astype(np.uint8)), \n",
    "                                                                  caption=\"HR Downsampled\"),\n",
    "                                \"images/sr_xy\": wandb.Image(np.squeeze(generated_xy_np[0].astype(np.uint8)), \n",
    "                                                          caption=\"SR XY\"),\n",
    "                                \"images/sr_xyz\": wandb.Image(np.squeeze(generated_xyz_np[0].astype(np.uint8)), \n",
    "                                                           caption=\"SR XYZ\"),\n",
    "                            }, step=global_step)\n",
    "                        \n",
    "                        val_pbar.set_postfix({\n",
    "                            'PSNR-SR': f\"{psnr_xy.item():.4f}\", \n",
    "                            'PSNR-SRC': f\"{psnr_xyz.item():.4f}\"\n",
    "                        })\n",
    "                        val_pbar.update(1)\n",
    "                        \n",
    "                        if num_test_batches >= args.valNum:\n",
    "                            break\n",
    "                val_pbar.close()\n",
    "                \n",
    "                # Calculate average validation metrics\n",
    "                val_psnr_xy /= num_test_batches\n",
    "                val_psnr_xyz /= num_test_batches\n",
    "                val_l1_loss = val_l1_loss_total / num_test_batches\n",
    "                \n",
    "                # Update validation metrics\n",
    "                val_metrics['epoch'].append(epoch+1)\n",
    "                val_metrics['psnr_xy'].append(val_psnr_xy)\n",
    "                val_metrics['psnr_xyz'].append(val_psnr_xyz)\n",
    "                val_metrics['l1_loss'].append(val_l1_loss)\n",
    "                val_metrics['global_step'].append(global_step)\n",
    "                \n",
    "                stdout.write(\"\\n\")\n",
    "                print(f'Mean Validation PSNR-SR: {val_psnr_xy}, PSNR-SRC: {val_psnr_xyz}, L1-Loss: {val_l1_loss}')\n",
    "                \n",
    "                # Log validation metrics to wandb\n",
    "                wandb.log({\n",
    "                    \"val/psnr_xy\": val_psnr_xy,\n",
    "                    \"val/psnr_xyz\": val_psnr_xyz,\n",
    "                    \"val/l1_loss\": val_l1_loss\n",
    "                }, step=global_step)\n",
    "\n",
    "                # Use weighted score for model selection (PSNR and L1 loss)\n",
    "                psnr_weight = 0.7\n",
    "                l1_weight = 0.3\n",
    "                current_score = (psnr_weight * val_psnr_xyz) - (l1_weight * val_l1_loss)\n",
    "                best_score = (psnr_weight * best_model['val_psnr_xyz']) - (l1_weight * best_model['val_l1_loss'])\n",
    "\n",
    "                if current_score > best_score:\n",
    "                    best_model['epoch'] = epoch + 1\n",
    "                    best_model['val_psnr_xyz'] = val_psnr_xyz\n",
    "                    best_model['val_psnr_xy'] = val_psnr_xy\n",
    "                    best_model['val_l1_loss'] = val_l1_loss\n",
    "                    \n",
    "                    print(f\"\\nNew best model at epoch {epoch+1}!\")\n",
    "                    print(f\"PSNR-XY: {val_psnr_xy:.4f}, PSNR-XYZ: {val_psnr_xyz:.4f}, L1 Loss: {val_l1_loss:.4f}\")\n",
    "                    \n",
    "                    # Save best models\n",
    "                    torch.save(generator_sr.state_dict(), f'{training_dir}/GSR-best.pth')\n",
    "                    torch.save(generator_src.state_dict(), f'{training_dir}/GSRC-best.pth')\n",
    "                    \n",
    "                    # Full checkpoint for potential resuming\n",
    "                    torch.save({\n",
    "                        'epoch': epoch+1,\n",
    "                        'model_state_dict': generator_sr.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer_gen_sr.state_dict(),\n",
    "                        'best_psnr': val_psnr_xyz,\n",
    "                        'best_l1': val_l1_loss\n",
    "                    }, f'{training_dir}/GSR-best_full.pth')\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'epoch': epoch+1,\n",
    "                        'model_state_dict': generator_src.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer_gen_src.state_dict(),\n",
    "                        'best_psnr': val_psnr_xyz,\n",
    "                        'best_l1': val_l1_loss\n",
    "                    }, f'{training_dir}/GSRC-best_full.pth')\n",
    "                    \n",
    "                    # Log best metrics to wandb\n",
    "                    wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
    "                    wandb.run.summary[\"best_psnr_xyz\"] = val_psnr_xyz\n",
    "                    wandb.run.summary[\"best_psnr_xy\"] = val_psnr_xy\n",
    "                    wandb.run.summary[\"best_l1_loss\"] = val_l1_loss\n",
    "                    \n",
    "                    # Additionally log as metrics\n",
    "                    wandb.log({\n",
    "                        \"best/epoch\": epoch + 1,\n",
    "                        \"best/psnr_xyz\": val_psnr_xyz,\n",
    "                        \"best/psnr_xy\": val_psnr_xy,\n",
    "                        \"best/l1_loss\": val_l1_loss\n",
    "                    }, step=global_step)\n",
    "                \n",
    "                # Test on separate test data if enabled\n",
    "                if args.valTest and 'LR_test' in locals():\n",
    "                    print(f'Generating some test cubes')\n",
    "                    with torch.no_grad():\n",
    "                        test_sr_xy = generator_sr(LR_test)\n",
    "                        test_sr_xy_np = test_sr_xy.cpu().numpy()\n",
    "                        image_path = f'./{train_output_dir}/epoch-{epoch+1}/testSRxy.tif'\n",
    "                        test_sr_xy_out = (test_sr_xy_np + 1) * 127.5\n",
    "                        tifffile.imwrite(image_path, np.squeeze(test_sr_xy_out.astype('uint8')))\n",
    "                        \n",
    "                        # Log test image to wandb\n",
    "                        wandb.log({\n",
    "                            \"test/sr_xy\": wandb.Image(np.squeeze(test_sr_xy_out[0].astype(np.uint8)), \n",
    "                                                    caption=\"Test SR XY\"),\n",
    "                        }, step=global_step)\n",
    "            \n",
    "            # Save models periodically\n",
    "            if (epoch+1) % args.save_freq == 0 or epoch == args.epoch - 1:\n",
    "                print('Saving network weights (archive)')\n",
    "                torch.save(generator_sr.state_dict(), f'{training_dir}/GSR-{epoch+1}.pth')\n",
    "                torch.save(generator_src.state_dict(), f'{training_dir}/GSRC-{epoch+1}.pth')\n",
    "                \n",
    "                print('Saving network weights (rewritable checkpoint)')\n",
    "                torch.save(generator_sr.state_dict(), f'{training_dir}/GSR.pth')\n",
    "                torch.save(generator_src.state_dict(), f'{training_dir}/GSRC.pth')\n",
    "                \n",
    "                print('Saving model (rewritable checkpoint)')\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'model_state_dict': generator_sr.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer_gen_sr.state_dict(),\n",
    "                }, f'{training_dir}/GSR-{epoch+1}_full.pth')\n",
    "                \n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'model_state_dict': generator_src.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer_gen_src.state_dict(),\n",
    "                }, f'{training_dir}/GSRC-{epoch+1}_full.pth')\n",
    "                \n",
    "                # Save model checkpoint to wandb\n",
    "                wandb.save(f'{training_dir}/GSR-{epoch+1}.pth')\n",
    "                wandb.save(f'{training_dir}/GSRC-{epoch+1}.pth')\n",
    "\n",
    "            # Update the learning rate after each epoch\n",
    "            scheduler_gen_sr.step()\n",
    "            scheduler_gen_src.step()\n",
    "                \n",
    "        # After training is completed\n",
    "        # Create directory for storing metrics\n",
    "        os.makedirs(f'{train_output_dir}/metrics', exist_ok=True)\n",
    "\n",
    "        # Save training losses\n",
    "        train_df = pd.DataFrame(train_losses)\n",
    "        train_df.to_csv(f'{train_output_dir}/metrics/training_losses.csv', index=False)\n",
    "        print(f\"Training losses saved to {train_output_dir}/metrics/training_losses.csv\")\n",
    "\n",
    "        # Save validation metrics\n",
    "        val_df = pd.DataFrame(val_metrics)\n",
    "        val_df.to_csv(f'{train_output_dir}/metrics/validation_metrics.csv', index=False)\n",
    "        print(f\"Validation metrics saved to {train_output_dir}/metrics/validation_metrics.csv\")\n",
    "        \n",
    "        # Save batch-level losses for more detailed analysis\n",
    "        batch_df = pd.DataFrame(batch_losses)\n",
    "        batch_df.to_csv(f'{train_output_dir}/metrics/batch_losses.csv', index=False)\n",
    "        print(f\"Batch-level losses saved to {train_output_dir}/metrics/batch_losses.csv\")\n",
    "\n",
    "        # Create a basic plot as a quick reference\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            # Plot training loss\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            \n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(train_df['epoch'], train_df['sr_xy_loss'], 'b-', label='XY Loss')\n",
    "            plt.plot(train_df['epoch'], train_df['sr_yz_loss'], 'r-', label='YZ Loss')\n",
    "            plt.plot(train_df['epoch'], train_df['total_loss'], 'g-', label='Total Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training Losses')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot validation metrics\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(val_df['epoch'], val_df['psnr_xy'], 'b-o', label='PSNR XY')\n",
    "            plt.plot(val_df['epoch'], val_df['psnr_xyz'], 'r-o', label='PSNR XYZ')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('PSNR (dB)')\n",
    "            plt.title('Validation PSNR')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot learning rate schedule\n",
    "            plt.subplot(2, 2, 3)\n",
    "            # Extract learning rates - recreate the schedule curve\n",
    "            epochs = np.arange(1, args.epoch + 1)\n",
    "            lrs = []\n",
    "            \n",
    "            # Create a temporary optimizer and scheduler to simulate LR curve\n",
    "            temp_optimizer = optim.Adam([torch.nn.Parameter(torch.zeros(1))], lr=args.lr)\n",
    "            temp_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                temp_optimizer, T_0=args.epoch_step, T_mult=2, eta_min=args.eta_min\n",
    "            )\n",
    "            \n",
    "            # Simulate scheduler steps\n",
    "            for _ in epochs:\n",
    "                lrs.append(temp_optimizer.param_groups[0]['lr'])\n",
    "                temp_scheduler.step()\n",
    "                \n",
    "            plt.plot(epochs, lrs, 'g-')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.title('Cosine Annealing Warm Restarts Learning Rate Schedule')\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot batch-level losses (smoothed)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            window_size = 50  # Moving average window for smoothing\n",
    "            if len(batch_df) > window_size:\n",
    "                plt.plot(batch_df['global_step'], batch_df['sr_xy_loss'].rolling(window=window_size).mean(), 'b-', alpha=0.7, label=f'XY Loss (MA{window_size})')\n",
    "                plt.plot(batch_df['global_step'], batch_df['sr_yz_loss'].rolling(window=window_size).mean(), 'r-', alpha=0.7, label=f'YZ Loss (MA{window_size})')\n",
    "                plt.plot(batch_df['global_step'], batch_df['total_loss'].rolling(window=window_size).mean(), 'g-', alpha=0.7, label=f'Total Loss (MA{window_size})')\n",
    "                plt.xlabel('Global Step')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.title('Batch-level Losses (Moving Average)')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "            else:\n",
    "                plt.title('Not enough batches for smoothed visualization')\n",
    "                plt.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{train_output_dir}/metrics/training_summary.png', dpi=300)\n",
    "            plt.close()\n",
    "            print(f\"Summary plot saved to {train_output_dir}/metrics/training_summary.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create summary plot: {str(e)}\")\n",
    "        wandb.finish()\n",
    "\n",
    "    # Test on larger volumes - save as 3D TIFF\n",
    "    elif args.phase == 'test':\n",
    "        # Set models to evaluation mode\n",
    "        generator_sr.eval()\n",
    "        generator_src.eval()\n",
    "        \n",
    "        # Find test files\n",
    "        test_files = sorted(glob(args.test_dir + '/*.png'))\n",
    "        if not test_files:\n",
    "            print(f\"No PNG files found in {args.test_dir}\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Found {len(test_files)} test files\")\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(os.path.join(args.test_save_dir, args.modelName), exist_ok=True)\n",
    "        \n",
    "        # Check available RAM before processing\n",
    "        mem_info = psutil.virtual_memory()\n",
    "        available_ram_gb = mem_info.available / 1e9\n",
    "        print(f\"Available RAM: {available_ram_gb:.1f} GB\")\n",
    "        \n",
    "        # Estimate memory needed based on test file size\n",
    "        test_sample = imageio.imread(test_files[0])\n",
    "        bytes_per_voxel = 4  # float32\n",
    "        vol_shape_xy = (len(test_files), test_sample.shape[0] * args.scale, test_sample.shape[1] * args.scale)\n",
    "        estimated_peak_gb = (vol_shape_xy[0] * vol_shape_xy[1] * vol_shape_xy[2] * bytes_per_voxel * 2) / 1e9\n",
    "        print(f\"Estimated peak memory usage: {estimated_peak_gb:.1f} GB\")\n",
    "        \n",
    "        # Choose processing method based on available RAM\n",
    "        if available_ram_gb > estimated_peak_gb * 1.5:  # Add 50% safety margin\n",
    "            print(f\"Sufficient RAM available. Processing volume directly without chunking.\")\n",
    "            output_volume = process_entire_volume(test_files, generator_sr, generator_src, args, device)\n",
    "        else:\n",
    "            print(f\"Limited RAM available ({available_ram_gb:.1f} GB). Using chunked processing.\")\n",
    "            output_volume = test_memory_efficient_3d(test_files, generator_sr, generator_src, args, device)\n",
    "        \n",
    "        # Test metrics calculation if ground truth is available\n",
    "        gt_dir = os.path.join(os.path.dirname(args.test_dir), 'HR')\n",
    "        gt_files = sorted(glob(f\"{gt_dir}/*.png\"))\n",
    "        \n",
    "        if gt_files and len(gt_files) * args.scale == output_volume.shape[0]:\n",
    "            print(\"Found ground truth files. Calculating metrics...\")\n",
    "            \n",
    "            # Load ground truth volume\n",
    "            gt_volume = []\n",
    "            for gt_file in tqdm(gt_files, desc=\"Loading ground truth\"):\n",
    "                gt_slice = imageio.imread(gt_file)\n",
    "                # Ensure same size as output\n",
    "                if gt_slice.shape != (output_volume.shape[1], output_volume.shape[2]):\n",
    "                    print(f\"Warning: GT size mismatch. Resizing GT from {gt_slice.shape} to match output {output_volume.shape[1:]}\")\n",
    "                    # You might want to add resizing here if needed\n",
    "                gt_volume.append(gt_slice)\n",
    "            \n",
    "            # Convert stacks to volume\n",
    "            gt_slices = np.stack(gt_volume, axis=0)\n",
    "            gt_volume = np.zeros((output_volume.shape[0], output_volume.shape[1], output_volume.shape[2]), dtype=np.uint8)\n",
    "            \n",
    "            # Interpolate along Z to match output scale\n",
    "            for y in range(output_volume.shape[1]):\n",
    "                for x in range(output_volume.shape[2]):\n",
    "                    gt_profile = gt_slices[:, y, x]\n",
    "                    gt_volume[:, y, x] = np.interp(\n",
    "                        np.linspace(0, len(gt_profile)-1, output_volume.shape[0]),\n",
    "                        np.arange(len(gt_profile)),\n",
    "                        gt_profile\n",
    "                    )\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse = np.mean((output_volume.astype(np.float32) - gt_volume.astype(np.float32)) ** 2)\n",
    "            psnr = 20 * np.log10(255.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "            mae = np.mean(np.abs(output_volume.astype(np.float32) - gt_volume.astype(np.float32)))\n",
    "            \n",
    "            print(f\"Test metrics - PSNR: {psnr:.4f}, MAE: {mae:.4f}\")\n",
    "            \n",
    "            # Save metrics to CSV\n",
    "            metrics_df = pd.DataFrame({\n",
    "                'metric': ['PSNR', 'MAE', 'MSE'],\n",
    "                'value': [psnr, mae, mse],\n",
    "                'model': args.modelName,\n",
    "                'dataset': os.path.basename(args.test_dir)\n",
    "            })\n",
    "            metrics_df.to_csv(f'{args.test_save_dir}/{args.modelName}/test_metrics.csv', index=False)\n",
    "            \n",
    "            print(f\"Test metrics saved to {args.test_save_dir}/{args.modelName}/test_metrics.csv\")\n",
    "        \n",
    "        print(f\"Testing completed. Results saved to {args.test_save_dir}/{args.modelName}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f2191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API key provided. Using default wandb login...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmzz20\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully authenticated with wandb!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jm3421/superResolution/wandb/run-20250421_125653-ugsf7uds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mzz20/DualSR_Bentheimer_mixed90/runs/ugsf7uds' target=\"_blank\">DualSR_mixed90-20250421-125652</a></strong> to <a href='https://wandb.ai/mzz20/DualSR_Bentheimer_mixed90' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mzz20/DualSR_Bentheimer_mixed90' target=\"_blank\">https://wandb.ai/mzz20/DualSR_Bentheimer_mixed90</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mzz20/DualSR_Bentheimer_mixed90/runs/ugsf7uds' target=\"_blank\">https://wandb.ai/mzz20/DualSR_Bentheimer_mixed90/runs/ugsf7uds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D/3D training specified, datasets will be randomly mini-batched per epoch\n",
      "2D/3D dataset and training -> data will be fully preloaded into RAM\n",
      "Loading LR data from: ./Dataset/Bentheimer_mixed_fw90/Train/LR.npy\n",
      "Loading HR data from: ./Dataset/Bentheimer_mixed_fw90/Train/HR.npy\n",
      "LR shape: (250, 250, 250), HR shape: (1000, 1000, 1000)\n",
      "Reading dataset, block size this epoch: 103 x 75 x 75 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a0d298dc5c4ea9990866357723c651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 1.000000e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa53c656a8ca49e1827fd2d8ae5b8035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0731, GSRyzL: 0.0938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56f7c6b15224ecaa5bd1b7499fcad1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 29.63341407775879, PSNR-SRC: 27.83168716430664, L1-Loss: 0.05053101554512977\n",
      "\n",
      "New best model at epoch 1!\n",
      "PSNR-XY: 29.6334, PSNR-XYZ: 27.8317, L1 Loss: 0.0505\n",
      "Reading dataset, block size this epoch: 110 x 73 x 73 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be1e88e7b08488e91536c163eaf4688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.990232e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265850f2bdf24f0fa320444655935a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0463, GSRyzL: 0.0504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a16b26306443f7a9e671a09b774301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 31.902999114990234, PSNR-SRC: 30.073437881469726, L1-Loss: 0.03856193497776985\n",
      "\n",
      "New best model at epoch 2!\n",
      "PSNR-XY: 31.9030, PSNR-XYZ: 30.0734, L1 Loss: 0.0386\n",
      "Reading dataset, block size this epoch: 72 x 90 x 90 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e692618d9d4b3d8bed2245719bbdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.960968e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239f297204c141cd9ff8abe809b466b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0405, GSRyzL: 0.0445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a071098214b54c12916caadcd0765561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 32.447698974609374, PSNR-SRC: 30.733896255493164, L1-Loss: 0.03596896827220917\n",
      "\n",
      "New best model at epoch 3!\n",
      "PSNR-XY: 32.4477, PSNR-XYZ: 30.7339, L1 Loss: 0.0360\n",
      "Reading dataset, block size this epoch: 78 x 86 x 86 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0883dd96abcd4407b29f4a387c7f1e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.912322e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae1dc9ff5754bc4b4f8b534a58808d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0384, GSRyzL: 0.0416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a236a5c3a54c67b86b0d7851e616a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 32.099238586425784, PSNR-SRC: 31.059212112426756, L1-Loss: 0.03483603671193123\n",
      "\n",
      "New best model at epoch 4!\n",
      "PSNR-XY: 32.0992, PSNR-XYZ: 31.0592, L1 Loss: 0.0348\n",
      "Reading dataset, block size this epoch: 174 x 58 x 58 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a324f0fbca1541f6a7a95f401c4cbb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.844487e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66385315e742c590fcacd8d71b4e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0370, GSRyzL: 0.0387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ab21c4742e4879944641aee6cef60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 33.36779098510742, PSNR-SRC: 32.40069923400879, L1-Loss: 0.03120445869863033\n",
      "\n",
      "New best model at epoch 5!\n",
      "PSNR-XY: 33.3678, PSNR-XYZ: 32.4007, L1 Loss: 0.0312\n",
      "Reading dataset, block size this epoch: 160 x 60 x 60 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53c88b6b9a2437da5dfcfb46a8757df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.757730e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bd5a8e4df7454e89451346d472232a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0352, GSRyzL: 0.0367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2a97dc0a0149ad819981d4c7eaaf94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 33.384098052978516, PSNR-SRC: 32.49186897277832, L1-Loss: 0.030090263485908507\n",
      "\n",
      "New best model at epoch 6!\n",
      "PSNR-XY: 33.3841, PSNR-XYZ: 32.4919, L1 Loss: 0.0301\n",
      "Reading dataset, block size this epoch: 107 x 74 x 74 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22634870be624c20bd927e649888f4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.652394e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1239004334d542dbbf49cd1ca6ee8c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0327, GSRyzL: 0.0345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cc36ba6dc84d19a84fd2e23179732d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.13421096801758, PSNR-SRC: 32.694484329223634, L1-Loss: 0.031065214797854422\n",
      "\n",
      "New best model at epoch 7!\n",
      "PSNR-XY: 34.1342, PSNR-XYZ: 32.6945, L1 Loss: 0.0311\n",
      "Reading dataset, block size this epoch: 31 x 137 x 137 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4257a7ed734618b518b722109753e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.528894e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec68452a5e145c8b82a5c949adfa743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0328, GSRyzL: 0.0353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02857c3ce434373bd9d21652c685ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.13420104980469, PSNR-SRC: 33.17862777709961, L1-Loss: 0.02962447181344032\n",
      "\n",
      "New best model at epoch 8!\n",
      "PSNR-XY: 34.1342, PSNR-XYZ: 33.1786, L1 Loss: 0.0296\n",
      "Reading dataset, block size this epoch: 177 x 57 x 57 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0694f6ef5e334d1995798a7bf3edec63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.387718e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc6044c6c744e829728e3afd0c2e342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0313, GSRyzL: 0.0326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78bd928fcc144709a2be02ac2d3a7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.125144958496094, PSNR-SRC: 33.439842987060544, L1-Loss: 0.02740780673921108\n",
      "\n",
      "New best model at epoch 9!\n",
      "PSNR-XY: 34.1251, PSNR-XYZ: 33.4398, L1 Loss: 0.0274\n",
      "Reading dataset, block size this epoch: 90 x 80 x 80 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1feba6957ec24ae2be859cb443a6dd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.229423e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d590abad6444d87a86d84ecd5f2ad4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0295, GSRyzL: 0.0303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418a788ea40d43ffa9abd9c896e127e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.06901473999024, PSNR-SRC: 33.48613510131836, L1-Loss: 0.027213162183761595\n",
      "\n",
      "New best model at epoch 10!\n",
      "PSNR-XY: 34.0690, PSNR-XYZ: 33.4861, L1 Loss: 0.0272\n",
      "Saving network weights (archive)\n",
      "Saving network weights (rewritable checkpoint)\n",
      "Saving model (rewritable checkpoint)\n",
      "Reading dataset, block size this epoch: 66 x 94 x 94 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ebe28909e14ee7a64f7cc7363eef3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 9.054634e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24f608cc1964cb88abe1725531e03a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0299, GSRyzL: 0.0309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b129290676495ebddeb71e241450ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 33.183695220947264, PSNR-SRC: 32.38807563781738, L1-Loss: 0.03517596200108528\n",
      "Reading dataset, block size this epoch: 44 x 115 x 115 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dee35df942f40559d55226e738a6aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 8.864041e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8205b640c64372b81ebeb1cacab434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0298, GSRyzL: 0.0306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a597d28a0004e64b582670b45b61cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.45735244750976, PSNR-SRC: 34.03599243164062, L1-Loss: 0.027611548081040382\n",
      "\n",
      "New best model at epoch 12!\n",
      "PSNR-XY: 34.4574, PSNR-XYZ: 34.0360, L1 Loss: 0.0276\n",
      "Reading dataset, block size this epoch: 150 x 62 x 62 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfcb73f164246e9a39c4ee51d70dc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 8.658395e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c79cdc0993b435ea4f51183a1fea92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0301, GSRyzL: 0.0309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fa6453bc67490784eff0b3a7e9d0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.42474365234375, PSNR-SRC: 34.074398803710935, L1-Loss: 0.02640445567667484\n",
      "\n",
      "New best model at epoch 13!\n",
      "PSNR-XY: 34.4247, PSNR-XYZ: 34.0744, L1 Loss: 0.0264\n",
      "Reading dataset, block size this epoch: 28 x 145 x 145 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edc9737eea5463ca2b1d653ef2162d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 8.438508e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c1f493b37f4d4c90dbb89bad06198f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0277, GSRyzL: 0.0283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7cfe4e505e45808e849910f4cd2900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.88988189697265, PSNR-SRC: 34.20419616699219, L1-Loss: 0.02734937407076359\n",
      "\n",
      "New best model at epoch 14!\n",
      "PSNR-XY: 34.8899, PSNR-XYZ: 34.2042, L1 Loss: 0.0273\n",
      "Reading dataset, block size this epoch: 134 x 66 x 66 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bda70ab4e904f128b54ca4db2655d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 8.205249e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbbc8e140ad4ce1ba7eab0d5b946f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0284, GSRyzL: 0.0284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47153ab88c47421c8aeb925b6569a3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.72739486694336, PSNR-SRC: 34.50938339233399, L1-Loss: 0.026596492156386375\n",
      "\n",
      "New best model at epoch 15!\n",
      "PSNR-XY: 34.7274, PSNR-XYZ: 34.5094, L1 Loss: 0.0266\n",
      "Reading dataset, block size this epoch: 44 x 115 x 115 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27805b3e281e41f8b27f460057c67419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 7.959537e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6555c8b570504448bdb039991ae80b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0278, GSRyzL: 0.0279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8087d5e9c6c34f3b810b23dba1c141d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.641578674316406, PSNR-SRC: 34.33411483764648, L1-Loss: 0.027170846611261366\n",
      "Reading dataset, block size this epoch: 109 x 73 x 73 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a211e04928a406db2dc9fc499f0c27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 7.702343e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d8b953b71643d7a46bdd0eb5f4a73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0288, GSRyzL: 0.0293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93861dffced34721bb5418f84cff2354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.064073944091795, PSNR-SRC: 33.96184158325195, L1-Loss: 0.027146874740719796\n",
      "Reading dataset, block size this epoch: 114 x 71 x 71 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb840eca33d54fb0b1bc4ab9fc428ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 7.434681e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0da2eb44d534b1095f8894eaddb22d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Epoch Performance: GSRxyL: 0.0275, GSRyzL: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269802831bab48b7aaa6bcd6096604db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Validation PSNR-SR: 34.96498565673828, PSNR-SRC: 34.94762496948242, L1-Loss: 0.023847226053476334\n",
      "\n",
      "New best model at epoch 18!\n",
      "PSNR-XY: 34.9650, PSNR-XYZ: 34.9476, L1 Loss: 0.0238\n",
      "Reading dataset, block size this epoch: 74 x 89 x 89 -> 4x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efaec75ee9514530a265ebfa93c35350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Training Cubes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 7.157607e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af935c50c42a4e0c834643fa1a5b818e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/500:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add this at the end of your notebook as a separate cell\n",
    "if __name__ == \"__main__\":\n",
    "    args = Args()\n",
    "    # Set your API key here or pass it as an argument to your script\n",
    "    args.wandb_api_key = os.environ.get(\"WANDB_API_KEY\")  \n",
    "    # Optional: specify your wandb entity (username or team name)\n",
    "    args.wandb_entity = \"YOUR_WANDB_USERNAME\"  \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87611b72-5f3f-4905-9ed4-2eccd1bdc43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(seg)",
   "language": "python",
   "name": "seg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
